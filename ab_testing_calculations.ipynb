{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c05276e4",
   "metadata": {},
   "source": [
    "# PYTHON. Calculations for AB test analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1945043",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as st\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ca0374",
   "metadata": {},
   "source": [
    "## Basic theoretical confidence interval calculation\n",
    "Assumptions: Normal distribution (functions from **scipy.stats** library)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0e34ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_interval(clicks, N, conf=0.95, n_tails=2, rnd=4):\n",
    "    # ppf(q, loc=0, scale=1) Percent point function (inverse of cdf â€” percentiles).\n",
    "    z=st.norm.ppf(1-(1-conf)/n_tails)\n",
    "\n",
    "    p_hat=clicks/N\n",
    "    # binomial distribution\n",
    "    standard_error= math.sqrt(p_hat*(1-p_hat)/N)\n",
    "\n",
    "    margin_of_error = standard_error * z\n",
    "\n",
    "    lower = p_hat - margin_of_error\n",
    "    upper = p_hat + margin_of_error\n",
    "\n",
    "    #st.norm.cdf(z)\n",
    "    print(f'P_hat:           {round(p_hat,4)}')\n",
    "    print(f'Standard error:  {round(standard_error,4)}')\n",
    "    print(f'Margin of error: {round(margin_of_error,4)}')\n",
    "    print(\"-\"*20)\n",
    "    print(f\"{round(conf*100,1)}% {n_tails}-tail confidence interval is [{round(lower,rnd)} ; {round(upper,4)}]\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb62edaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P_hat:           0.15\n",
      "Standard error:  0.008\n",
      "Margin of error: 0.0206\n",
      "--------------------\n",
      "99.0% 2-tail confidence interval is [0.1294 ; 0.1706]\n"
     ]
    }
   ],
   "source": [
    "N=2000\n",
    "clicks=300\n",
    "conf=0.99\n",
    "n_tails=2\n",
    "\n",
    "conf_interval(clicks, N, conf=conf, n_tails=n_tails)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba56d08f",
   "metadata": {},
   "source": [
    "## Sample size\n",
    "How many observations (at least) need to be collected to have significant results?\n",
    "\n",
    "* [Even Miller calculator](https://www.evanmiller.org/ab-testing/sample-size.html)\n",
    "* calculation based on pooled standard error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba7f76ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://towardsdatascience.com/mathematical-intuition-behind-a-b-testing-with-python-9d024e5e7f37\n",
    "\n",
    "def calc_sample_size(alpha, beta, p, delta, method, n_tails=2):\n",
    "    \"\"\" Based on https://www.evanmiller.org/ab-testing/sample-size.html\n",
    "    Ref: https://stats.stackexchange.com/questions/357336/create-an-a-b-sample-size-calculator-using-evan-millers-post\n",
    "    Args:\n",
    "        alpha (float): How often are you willing to accept a Type I error (false positive)?\n",
    "        power (float): How often do you want to correctly detect a true positive (=1-beta)?\n",
    "        p (float): Base conversion rate\n",
    "        pct_mde (float): Minimum detectable effect, relative to base conversion rate.\n",
    "    \"\"\"\n",
    "    if method == 'evanmiller':\n",
    "        t_alpha2 = st.norm.ppf(1.0-alpha/n_tails)\n",
    "        t_beta = st.norm.ppf(1-beta)\n",
    "\n",
    "        sd1 = np.sqrt(2 * p * (1.0 - p))\n",
    "        sd2 = np.sqrt(p * (1.0 - p) + (p + delta) * (1.0 - p - delta))\n",
    "\n",
    "        n= round((t_alpha2 * sd1 + t_beta * sd2) * (t_alpha2 * sd1 + t_beta * sd2) / (delta**2))\n",
    "    elif method == 'pooled_se':\n",
    "        \"\"\"\n",
    "        References:\n",
    "            Code taken from Nguyen Ngo: https://towardsdatascience.com/the-math-behind-a-b-testing-with-example-code-part-1-of-2-7be752e1d06f\n",
    "            Stanford lecture on sample sizes     \n",
    "        \"\"\"\n",
    "        # standard normal distribution to determine z-values\n",
    "        standard_norm = st.norm(0, 1)\n",
    "\n",
    "        # find Z_beta from desired power\n",
    "        Z_beta = standard_norm.ppf(1-beta)\n",
    "\n",
    "        # find Z_alpha\n",
    "        Z_alpha = standard_norm.ppf(1-alpha/n_tails)\n",
    "\n",
    "        # average of probabilities from both groups\n",
    "        pooled_prob = (p + p+delta) / 2\n",
    "\n",
    "        n= round(2*(pooled_prob * (1 - pooled_prob) * (Z_beta + Z_alpha)**2\n",
    "                 / delta**2))\n",
    "    return n\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9da3e192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample size \n",
      "1) Evan Miller: 3623  \n",
      "2) Pooled_se:  3842 \n",
      "Average: 3732\n"
     ]
    }
   ],
   "source": [
    "alpha=0.05\n",
    "beta=0.2\n",
    "power=1-beta\n",
    "d_min=0.02 # delta\n",
    "p_hat=0.1\n",
    "pct_mde=p_hat-d_min/p_hat\n",
    "delta=d_min\n",
    "\n",
    "n_evanmiller=calc_sample_size(alpha, beta, p_hat, d_min, method='evanmiller')\n",
    "n_stanford=calc_sample_size(alpha, beta, p_hat, d_min, method='pooled_se')\n",
    "\n",
    "print (f\"Sample size \\n1) Evan Miller: {n_evanmiller}  \\n2) Pooled_se:  {n_stanford} \\nAverage: {round(np.mean([n_stanford,n_evanmiller]))}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503ac852",
   "metadata": {},
   "source": [
    "## AB test experiment analysis\n",
    "\n",
    "Pooled Standard error theoretical confidence interval calculation and comparison to practical minimal uplift. \n",
    "Verdict on the further actions based on the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d9d5757",
   "metadata": {},
   "outputs": [],
   "source": [
    "#theoretical\n",
    "def ab_pooled_theor_sign(N_cont, action_cont, N_exp, action_exp, d_min, conf=0.95, n_tails=2):\n",
    "    print(f\"Control \\n N      {N_cont}\\n action {action_cont}\")\n",
    "    print(f\"Experiment \\n N      {N_exp}\\n action {action_exp}\")\n",
    "    print(\"-\"*20)\n",
    "    \n",
    "    p_hat_cont=action_cont/N_cont\n",
    "    print(f\"P control:    {round(p_hat_cont,4)}\")\n",
    "\n",
    "    p_hat_exp=action_exp/N_exp\n",
    "    print(f\"P experiment: {round(p_hat_exp,4)}\")\n",
    "\n",
    "    p_hat_pool=(action_cont+action_exp)/(N_cont+N_exp)\n",
    "    print(f\"P poopled:    {round(p_hat_pool,4)}\")\n",
    "\n",
    "    standard_error_pool=math.sqrt(p_hat_pool*(1-p_hat_pool)*((1/N_cont) + (1/N_exp)))\n",
    "\n",
    "    z=st.norm.ppf(1-(1-conf)/n_tails)\n",
    "    margin_of_error_pool = standard_error_pool * z\n",
    "\n",
    "    dif_hat=p_hat_exp-p_hat_cont\n",
    "\n",
    "    p_min=dif_hat-margin_of_error_pool\n",
    "    p_max=dif_hat+margin_of_error_pool\n",
    "    print(\"-\"*20)\n",
    "    print(f'Minimal practical significance {round(d_min,4)}')\n",
    "    print(f\"Confidence interval [{round(p_min,4)},{round(p_max,4)}]\")\n",
    "    \n",
    "    print(\"-\"*20)\n",
    "    #stat significance - interval doesn't contain zero\n",
    "    if p_min<0 and p_max>0:\n",
    "        print(\"Confidence interval contains zero. We cannot reject null hypotesis that there is no difference between groups\")\n",
    "    elif p_min>0:\n",
    "        print(\"There is a significant positive result\")\n",
    "    else:   \n",
    "        print(\"There is a significant negative result\")\n",
    "\n",
    "\n",
    "    #practical significance   - the interval is to the right from min uplift\n",
    "    if d_min<=p_min:\n",
    "        print(f\"With {conf*100}% confidence there is practical and significant effect greater than d_min ({d_min}). \\nVerdict: LAUNCH the change\")\n",
    "    elif p_min>=-d_min and p_max<=d_min:\n",
    "        print(\"There is no practical significance. \\nVerdict: NO LAUNCH\")\n",
    "    elif p_min<=-d_min and p_max>=d_min:\n",
    "        print (\"Overlap. Results do not provide clarity. \\nVerdict: Additional test may bring more solid results\")\n",
    "    elif p_min>=-d_min and p_max>=d_min:\n",
    "        print (\"Intersection on positive side. Results do not provide clarity. \\nVerdict: Additional test may bring more solid results\")   \n",
    "    else: \n",
    "        print(\"No Launch\")\n",
    "    print(\"-\"*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c95c429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Control \n",
      " N      10072\n",
      " action 974\n",
      "Experiment \n",
      " N      9886\n",
      " action 1242\n",
      "--------------------\n",
      "P control:    0.0967\n",
      "P experiment: 0.1256\n",
      "P poopled:    0.111\n",
      "--------------------\n",
      "Minimal practical significance 0.02\n",
      "Confidence interval [0.0202,0.0376]\n",
      "--------------------\n",
      "There is a significant positive result\n",
      "With 95.0% confidence there is practical and significant effect greater than d_min (0.02). \n",
      "Verdict: LAUNCH the change\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "n_tails=2\n",
    "conf=0.95\n",
    "d_min=0.02\n",
    "#experiment --------------------------------------------------------------\n",
    "#control\n",
    "N_cont=10072 # pageviews\n",
    "action_cont=974 # clicks, views, etc\n",
    "\n",
    "#experiment (target)\n",
    "N_exp=9886 # pageviews\n",
    "action_exp=1242 #clicks, views, etc\n",
    "# calculations --------------------------------------------------------------\n",
    "\n",
    "ab_pooled_theor_sign(N_cont, action_cont, N_exp, action_exp, d_min)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021449cd",
   "metadata": {},
   "source": [
    "## Empirical confidence interval\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e8c4cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def empir_conf_interval(data, conf=0.95, n_tails=2, rnd=4):\n",
    "    N=len(data)\n",
    "    data_mean=np.mean(data)\n",
    "    data_std=np.std(data, ddof=1)\n",
    "    data_standard_error=data_std/np.sqrt(N)\n",
    "\n",
    "    # ppf(q, loc=0, scale=1) Percent point function (inverse of cdf â€” percentiles).\n",
    "    z=st.norm.ppf(1-(1-conf)/n_tails)\n",
    "    data_margin_of_error=z*data_standard_error\n",
    "\n",
    "\n",
    "    lower = data_mean - data_margin_of_error\n",
    "    upper = data_mean + data_margin_of_error\n",
    "    print(f\"{round(conf*100,1)}% {n_tails}-tail confidence interval is [{round(lower,rnd)} ; {round(upper,rnd)}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2fddb3da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.0% 2-tail confidence interval is [79158.0 ; 104367.0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data=[87029, 113407, 84843, 104994, 99327, 92052, 60684]\n",
    "conf=0.95\n",
    "n_tails=2\n",
    "\n",
    "empir_conf_interval(data, conf=0.95, n_tails=2, rnd=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39700330",
   "metadata": {},
   "source": [
    "## Variability analysis (bootstrap)\n",
    "\n",
    "**Bootstrap** - run one bigger experiment and then randomly split this large sample of users to smaller groups, calculate metric and compare results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d86dde5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_iterval_diff(data, conf=0.95, n_tails=2,rnd=4):\n",
    "    # theoretical confidence interval\n",
    "    N=len(data)\n",
    "    data_mean=np.mean(data)\n",
    "    data_std=np.std(data, ddof=1)\n",
    "    print(f\"Mean difference is {round(data_mean,rnd)} and standard deviation is {round(data_std,rnd)}\")\n",
    "\n",
    "    #Theoretical confidence interval\n",
    "    # ppf(q, loc=0, scale=1) Percent point function (inverse of cdf â€” percentiles).\n",
    "    z=st.norm.ppf(1-(1-conf)/n_tails)\n",
    "    data_margin_of_error=z*data_std\n",
    "\n",
    "\n",
    "    lower = data_mean - data_margin_of_error\n",
    "    upper = data_mean + data_margin_of_error\n",
    "    print(\"-\"*20)\n",
    "    print(\"Theoretical confidence interval\")\n",
    "    print(f\"{round(conf*100,1)}% {n_tails}-tail confidence interval is [{round(lower,rnd)} ; {round(upper,rnd)}]\")\n",
    "\n",
    "    # Empirical confidence interval (percentile)\n",
    "\n",
    "    ran=np.percentile(data,[2.5,97.5])\n",
    "    print(\"-\"*20)\n",
    "    print(\"Empirical confidence interval\")\n",
    "    print(f\"{round(conf*100,1)}% {n_tails}-tail confidence interval is [{round(ran[0],rnd)} ; {round(ran[1],rnd)}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2406732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean difference is 0.0042 and standard deviation is 0.0364\n",
      "--------------------\n",
      "Theoretical confidence interval\n",
      "95.0% 2-tail confidence interval is [-0.067 ; 0.0755]\n",
      "--------------------\n",
      "Empirical confidence interval\n",
      "95.0% 2-tail confidence interval is [-0.0605 ; 0.0802]\n"
     ]
    }
   ],
   "source": [
    "conf=0.95\n",
    "n_tails=2\n",
    "\n",
    "# test results\n",
    "g1=[0.02,0.11,0.14,0.05,0.09,0.11,0.09,0.1,0.14,0.08,0.09,0.08,0.09,0.08,0.12,0.09,0.16,0.11,0.12,0.11,0.06,0.11,0.13,0.1,0.08,0.14,0.1,0.08,0.12,0.09,0.14,0.1,0.08,0.08,0.07,0.13,0.11,0.08,0.1,0.11]\n",
    "g2=[0.07,0.11,0.05,0.07,0.1,0.07,0.1,0.1,0.12,0.14,0.04,0.07,0.07,0.06,0.15,0.09,0.12,0.1,0.08,0.09,0.08,0.08,0.14,0.09,0.1,0.08,0.08,0.09,0.08,0.11,0.11,0.1,0.14,0.1,0.08,0.05,0.19,0.11,0.08,0.13]\n",
    "\n",
    "# difference between A and B per test\n",
    "g_diff=[round(x[0]-x[1],2) for x in zip(g1,g2)]\n",
    "\n",
    "# g_diff=[0]*40\n",
    "# for i in range(40):\n",
    "#     g_diff[i]=round(g1[i]-g2[i],2)\n",
    "   \n",
    "conf_iterval_diff(g_diff, conf, n_tails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9e47db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
